{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## 你可以将向量视为标量值组成的列表"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import torch"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([-0.2103,  0.3444,  0.2444,  0.0700])"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn((4,))\n",
    "x"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 通过指定两个分量m和n来创建一个形状为mxn的矩阵"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.2712,  0.4759,  0.0083,  0.0977],\n",
      "        [-0.2603, -0.2380, -0.1181,  1.5081],\n",
      "        [ 0.0936,  0.9325,  0.1837,  0.6670]])\n",
      "tensor([[-0.2712, -0.2603,  0.0936],\n",
      "        [ 0.4759, -0.2380,  0.9325],\n",
      "        [ 0.0083, -0.1181,  0.1837],\n",
      "        [ 0.0977,  1.5081,  0.6670]])\n",
      "torch.float32\n"
     ]
    }
   ],
   "source": [
    "X = torch.randn((3, 4))\n",
    "print(X)\n",
    "print(X.T)\n",
    "print(X[0][0].dtype)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 给定具有相同形状的任意两个张量，任何按元素二元运算的结果都将是相同形状的张量"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2., 2., 2.],\n",
      "        [2., 2., 2.]])\n",
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.]])\n",
      "tensor([[3., 3., 3.],\n",
      "        [3., 3., 3.]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.ones((2, 3))\n",
    "y = x.clone()\n",
    "print(x + y)\n",
    "print(x * y)  # 两个矩阵的按元素乘法称为哈达玛积（Hadamard product）,数学符号⊙\n",
    "print(x + 2)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 计算其元素的和、均值"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.,  1.,  2.,  3.],\n",
      "         [ 4.,  5.,  6.,  7.],\n",
      "         [ 8.,  9., 10., 11.]],\n",
      "\n",
      "        [[12., 13., 14., 15.],\n",
      "         [16., 17., 18., 19.],\n",
      "         [20., 21., 22., 23.]]]) torch.Size([2, 3, 4])\n",
      "tensor(276.) torch.Size([])\n",
      "tensor([[12., 14., 16., 18.],\n",
      "        [20., 22., 24., 26.],\n",
      "        [28., 30., 32., 34.]]) torch.Size([3, 4])\n",
      "tensor([[12., 15., 18., 21.],\n",
      "        [48., 51., 54., 57.]]) torch.Size([2, 4])\n",
      "tensor([[ 6., 22., 38.],\n",
      "        [54., 70., 86.]]) torch.Size([2, 3])\n",
      "tensor([[[0.0000, 0.0714, 0.1250, 0.1667],\n",
      "         [0.2000, 0.2273, 0.2500, 0.2692],\n",
      "         [0.2857, 0.3000, 0.3125, 0.3235]],\n",
      "\n",
      "        [[1.0000, 0.9286, 0.8750, 0.8333],\n",
      "         [0.8000, 0.7727, 0.7500, 0.7308],\n",
      "         [0.7143, 0.7000, 0.6875, 0.6765]]])\n",
      "tensor([[[ 0.,  1.,  2.,  3.],\n",
      "         [ 4.,  5.,  6.,  7.],\n",
      "         [ 8.,  9., 10., 11.]],\n",
      "\n",
      "        [[12., 14., 16., 18.],\n",
      "         [20., 22., 24., 26.],\n",
      "         [28., 30., 32., 34.]]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.arange(24, dtype=torch.float32).reshape(2, 3, 4)\n",
    "print(x, x.shape)\n",
    "print(x.sum(), x.sum().shape)\n",
    "print(x.sum(axis=0), x.sum(axis=0).shape)\n",
    "print(x.sum(axis=1), x.sum(axis=1).shape)\n",
    "print(x.sum(axis=2), x.sum(axis=2).shape)\n",
    "print(x / x.sum(axis=0, keepdim=True))\n",
    "print(x.cumsum(axis=0))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.,  1.,  2.,  3.],\n",
      "         [ 4.,  5.,  6.,  7.],\n",
      "         [ 8.,  9., 10., 11.]],\n",
      "\n",
      "        [[12., 13., 14., 15.],\n",
      "         [16., 17., 18., 19.],\n",
      "         [20., 21., 22., 23.]]])\n",
      "tensor(11.5000)\n",
      "tensor([[ 6.,  7.,  8.,  9.],\n",
      "        [10., 11., 12., 13.],\n",
      "        [14., 15., 16., 17.]])\n",
      "tensor([[[0.0000, 0.0714, 0.1250, 0.1667],\n",
      "         [0.2000, 0.2273, 0.2500, 0.2692],\n",
      "         [0.2857, 0.3000, 0.3125, 0.3235]],\n",
      "\n",
      "        [[1.0000, 0.9286, 0.8750, 0.8333],\n",
      "         [0.8000, 0.7727, 0.7500, 0.7308],\n",
      "         [0.7143, 0.7000, 0.6875, 0.6765]]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.arange(24, dtype=torch.float32).reshape(2, 3, 4)\n",
    "print(x)\n",
    "print(x.mean())\n",
    "print(x.mean(axis=0))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 点积是相同位置的按元素乘积的和"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor(True)"
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.arange(4, dtype=torch.float32)\n",
    "y = torch.ones(4)\n",
    "torch.dot(x, y) == torch.sum(x * y)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 矩阵向量积与矩阵乘法"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-3.5781,  1.4247,  0.0386])\n"
     ]
    }
   ],
   "source": [
    "A = torch.randn((3, 4))\n",
    "x = torch.ones(4, dtype=torch.float32)\n",
    "print(torch.mv(A, x))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.3242,  0.3242,  0.3242,  0.3242,  0.3242],\n",
      "        [ 1.5266,  1.5266,  1.5266,  1.5266,  1.5266],\n",
      "        [-3.0302, -3.0302, -3.0302, -3.0302, -3.0302]])\n"
     ]
    }
   ],
   "source": [
    "A = torch.randn((3, 4))\n",
    "B = torch.ones((4, 5), dtype=torch.float32)\n",
    "print(torch.mm(A, B))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 向量的L2范数与矩阵的Frobenius范数"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(22.4944)\n",
      "tensor(22.4944)\n"
     ]
    }
   ],
   "source": [
    "x = torch.arange(12, dtype=torch.float32)\n",
    "print(torch.norm(x))\n",
    "X = torch.arange(12, dtype=torch.float32).reshape(3, 4)\n",
    "print(torch.norm(X))"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
