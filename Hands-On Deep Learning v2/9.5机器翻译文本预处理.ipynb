{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import collections\n",
    "import re\n",
    "import os\n",
    "import torch\n",
    "import d2l.torch as d2l\n",
    "from typing import List, Tuple"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 文本预处理"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go.\tVa !\n",
      "Hi.\tSalut !\n",
      "Run!\tCours !\n",
      "Run!\tCourez !\n",
      "Who?\tQui ?\n",
      "Wow!\tÇa alors !\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 加载文本\n",
    "d2l.DATA_HUB['fra-eng'] = (d2l.DATA_URL + 'fra-eng.zip',\n",
    "                           '94646ad1522d915e7b0f9296181140edcf86a4f5')\n",
    "\n",
    "def read_data_nmt():\n",
    "    data_dir = d2l.download_extract('fra-eng')\n",
    "    with open(os.path.join(data_dir, 'fra.txt'), 'r', encoding='utf-8') as f:\n",
    "        return f.read()\n",
    "\n",
    "raw_text = read_data_nmt()\n",
    "print(raw_text[:75])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "go .\tva !\n",
      "hi .\tsalut !\n",
      "run !\tcours !\n",
      "run !\tcourez !\n",
      "who ?\tqui ?\n",
      "wow !\tça alors !\n"
     ]
    }
   ],
   "source": [
    "# 预处理文本\n",
    "def preprocess_nmt(raw_text: str) -> str:\n",
    "    # 使用空格替换不间断空格\n",
    "    text = raw_text.replace('\\u202f', ' ').replace('\\xa0', ' ')\n",
    "    # 使用小写字母替换大写字母\n",
    "    text = text.lower()\n",
    "    # 在单词和标点符号之间插入空格\n",
    "    marks = set(',.?!')\n",
    "    text = [' ' + char if char in marks and i > 0 and text[i-1] != ' ' else char\n",
    "            for i, char in enumerate(text)]\n",
    "    return ''.join(text)\n",
    "\n",
    "text = preprocess_nmt(raw_text)\n",
    "print(text[:80])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 文本分词"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "data": {
      "text/plain": "([['go', '.'],\n  ['hi', '.'],\n  ['run', '!'],\n  ['run', '!'],\n  ['who', '?'],\n  ['wow', '!']],\n [['va', '!'],\n  ['salut', '!'],\n  ['cours', '!'],\n  ['courez', '!'],\n  ['qui', '?'],\n  ['ça', 'alors', '!']])"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def tokenize_nmt(text: str, num_examples: int) -> Tuple[List[int], List[int]]:\n",
    "    source, target = [], []\n",
    "    for i, line in enumerate(text.split('\\n')):\n",
    "        if 0 <= num_examples == len(source):\n",
    "            return source, target\n",
    "        parts = line.split('\\t')\n",
    "        if len(parts) < 2:\n",
    "            continue\n",
    "        source.append(parts[0].split(' '))\n",
    "        target.append(parts[1].split(' '))\n",
    "    return source, target\n",
    "\n",
    "source, target = tokenize_nmt(text, num_examples=-1)\n",
    "source[:6], target[:6]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 建立词表"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "src_vocab = d2l.Vocab(source, min_freq=2,\n",
    "                                  reserved_tokens=['<pad>', '<bos>', '<eos>'])\n",
    "tgt_vocab = d2l.Vocab(target, min_freq=2,\n",
    "                                  reserved_tokens=['<pad>', '<bos>', '<eos>'])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 文本编码"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "data": {
      "text/plain": "([[47, 4], [2944, 4], [435, 126], [435, 126], [90, 9], [3664, 126]],\n [[124, 34], [4183, 34], [579, 34], [5850, 34], [39, 7], [35, 386, 34]])"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "src_corpus = src_vocab[source]\n",
    "tgt_corpus = tgt_vocab[target]\n",
    "src_corpus[:6], tgt_corpus[:6]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 构建数据集"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unexpected EOF while parsing (2391291822.py, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001B[0;36m  Cell \u001B[0;32mIn[20], line 3\u001B[0;36m\u001B[0m\n\u001B[0;31m    if len(line) > num_steps:\u001B[0m\n\u001B[0m                             ^\u001B[0m\n\u001B[0;31mSyntaxError\u001B[0m\u001B[0;31m:\u001B[0m unexpected EOF while parsing\n"
     ]
    }
   ],
   "source": [
    "# 截断或填充文本序列\n",
    "def truncate_pad(line: List[int], num_steps: int, padding_token: int) -> List[int]:\n",
    "    if len(line) > num_steps:\n",
    "        return line[:num_steps]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
