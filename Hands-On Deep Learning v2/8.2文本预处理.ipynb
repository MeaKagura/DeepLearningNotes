{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import collections\n",
    "import re\n",
    "import torch\n",
    "import d2l.torch as d2l\n",
    "from typing import List, Tuple"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 预处理文本"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the time machine by h g wells\n",
      "unaccountable thing he took one of the small octagonal tables that\n"
     ]
    }
   ],
   "source": [
    "d2l.DATA_HUB['time_machine'] = (d2l.DATA_URL + 'time_machine', '090b5e7e70c295757f55df93cb0a180b9691891a')\n",
    "\n",
    "def read_time_machine():\n",
    "    with open('../data/timemachine.txt', 'r') as f:\n",
    "        lines = [re.sub('[^A-Za-z]+', ' ', line).strip().lower() for line in f.readlines()]\n",
    "    return lines\n",
    "\n",
    "lines = read_time_machine()\n",
    "print(lines[0])\n",
    "print(lines[233])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 文本分词"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['the', 'time', 'machine', 'by', 'h', 'g', 'wells']\n",
      "['t', 'h', 'e', ' ', 't', 'i', 'm', 'e', ' ', 'm', 'a', 'c', 'h', 'i', 'n', 'e', ' ', 'b', 'y', ' ', 'h', ' ', 'g', ' ', 'w', 'e', 'l', 'l', 's']\n",
      "['unaccountable', 'thing', 'he', 'took', 'one', 'of', 'the', 'small', 'octagonal', 'tables', 'that']\n",
      "['u', 'n', 'a', 'c', 'c', 'o', 'u', 'n', 't', 'a', 'b', 'l', 'e', ' ', 't', 'h', 'i', 'n', 'g', ' ', 'h', 'e', ' ', 't', 'o', 'o', 'k', ' ', 'o', 'n', 'e', ' ', 'o', 'f', ' ', 't', 'h', 'e', ' ', 's', 'm', 'a', 'l', 'l', ' ', 'o', 'c', 't', 'a', 'g', 'o', 'n', 'a', 'l', ' ', 't', 'a', 'b', 'l', 'e', 's', ' ', 't', 'h', 'a', 't']\n"
     ]
    }
   ],
   "source": [
    "def tokenize(lines: List[str], token: str) -> List[List[str]]:\n",
    "    if token == 'word':\n",
    "        return [line.split() for line in lines]\n",
    "    elif token == 'char':\n",
    "        return [list(line) for line in lines]\n",
    "    else:\n",
    "        return []\n",
    "\n",
    "tokens_word = tokenize(lines, 'word')\n",
    "tokens_char = tokenize(lines, 'char')\n",
    "print(tokens_word[0])\n",
    "print(tokens_char[0])\n",
    "print(tokens_word[233])\n",
    "print(tokens_char[233])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 构建词表"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [],
   "source": [
    "class Vocab:\n",
    "    def __init__(self, tokens: List[List[str]], min_freq: int, reversed_tokens: List[str]):\n",
    "        tokens = [token for line in tokens for token in line]\n",
    "        counter = collections.Counter(tokens)\n",
    "        self.token_freq = sorted(counter.items(), key=lambda x: x[1], reverse=True)\n",
    "        self.unk = 0\n",
    "        self.id_to_token =  ['unk'] + reversed_tokens\n",
    "        self.token_to_id = {token: idx for idx, token in enumerate(self.id_to_token)}\n",
    "        for token, freq in self.token_freq:\n",
    "            if freq < min_freq:\n",
    "                break\n",
    "            self.id_to_token.append(token)\n",
    "            self.token_to_id[token] = len(self.id_to_token) - 1\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.id_to_token)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        ret = []\n",
    "        if isinstance(item, (list, tuple)):\n",
    "            ret = [self[line] for line in item]\n",
    "        elif isinstance(item, str):\n",
    "            ret = self.token_to_id.get(item, self.unk)\n",
    "        elif isinstance(item, int):\n",
    "            ret = self.id_to_token[item]\n",
    "        return ret\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 3139], [16, 65]]\n",
      "[['the', 'i'], ['and', 'of']]\n"
     ]
    }
   ],
   "source": [
    "vocab = Vocab(tokens_word, 0, [])\n",
    "print(vocab[[['the', 'apple'], ['for', 'man']]])\n",
    "print(vocab[[[1, 2], [3, 4]]])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 文本编码"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "170580 28\n",
      "[3, 9, 2, 1, 3, 5, 13, 2, 1, 13]\n"
     ]
    }
   ],
   "source": [
    "def load_corpus_time_machine(max_tokens=-1):\n",
    "    lines = read_time_machine()\n",
    "    tokens = tokenize(lines, 'char')\n",
    "    vocab = Vocab(tokens, 0, [])\n",
    "    corpus = [vocab[token] for line in tokens for token in line]\n",
    "    if max_tokens > 0:\n",
    "        corpus = corpus[: max_tokens]\n",
    "    return corpus, vocab\n",
    "\n",
    "corpus, vocab = load_corpus_time_machine()\n",
    "print(len(corpus), len(vocab))\n",
    "print(corpus[:10])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
